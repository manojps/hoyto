<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Checkpointing on Hoyto ...</title>
    <link>http://localhost:1313/docs/ml/checkpointing/</link>
    <description>Recent content in Checkpointing on Hoyto ...</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/docs/ml/checkpointing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CheckFreq</title>
      <link>http://localhost:1313/docs/ml/checkpointing/checkfreq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/ml/checkpointing/checkfreq/</guid>
      <description>&lt;h2 id=&#34;implementing-checkfreqs-asynchronous-ml-checkpointing-in-darknet&#34;&gt;&#xA;  Implementing CheckFreq&amp;rsquo;s asynchronous ML checkpointing in Darknet&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#implementing-checkfreqs-asynchronous-ml-checkpointing-in-darknet&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;I have recently implemented &lt;a href=&#34;https://www.usenix.org/conference/fast21/presentation/mohan&#34; target=&#34;_blank&#34; &gt;CheckFreq&lt;/a&gt;, an asynchronous checkpointing library for Deep Neural Networks (DNN), on top of &lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34; target=&#34;_blank&#34; &gt;Darknet&lt;/a&gt;, an open source neural network framework written in C and CUDA. Below are some high-level details about the implementation and one important lesson about CUDA concurrency.&lt;/p&gt;&#xA;&lt;p&gt;Darknet handles model checkpointing synchronously, where a checkpoint can only start after the weight update completes in an iteration and the next iteration does not start until the checkpoint operation completes. In contrast, CheckFreq proposes an two-stage asynchronous checkpointing method where the checkpoint operation executes in the background and only the weight update operation of the next iteration has to wait until the first stage (i.e., the snapshot operation that copies the model state in new memory pages in GPU or CPU) completes. This wait is called the snapshot stall. The second stage (i.e., the persist stage that writes the model state in GPU or CPu memory to files in persistent storage) can execute in the background without blocking any other operation. Implementing this correctly in Darknet involved three things.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
