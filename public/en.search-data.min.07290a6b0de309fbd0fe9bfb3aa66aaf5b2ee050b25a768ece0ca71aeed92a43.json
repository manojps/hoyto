[{"id":0,"href":"/docs/dsa/data_structure/binary_tree/insert/","title":"Insert","section":"Binary Tree","content":" Insert node # "},{"id":1,"href":"/docs/dsa/data_structure/linked_list/","title":"Linked List","section":"Data Structures","content":" Linked List # Sentinel node # "},{"id":2,"href":"/docs/dsa/data_structure/linked_list/insert/","title":"Insert","section":"Linked List","content":" Insert node in linked list # "},{"id":3,"href":"/docs/ml/checkpointing/","title":"Checkpointing","section":"Machine Learning","content":"List of state-of-the-art checkpointing and failure recovery mechanism for machine learning.\nCheckFreq # Paper | Code\nCheck-N-Run # Paper\nGPM # Paper | Code\nSwift # Paper\nLightCheck # Paper | Code\n"},{"id":4,"href":"/docs/dsa/data_structure/binary_tree/traverse/","title":"Traverse","section":"Binary Tree","content":" Traverse Binary Tree # class TreeNode: def __init__(self, val): self.val = val self.left = None self.right = None def visit(self): print(self.val) BFS traversal # Level-order traversal # DFS traversal # DFS traversal of a binary tree can be used to solve the following problems.\nMaximum width, minimum depth and diameter of a binary tree Binary tree iterator Convert a binary tree into a mirror tree Find k smallest/largest elements of a binary search tree Boundary traversal of binary tree Lowest common ancestor of two nodes in a binary tree Construct a binary tree from pre-order and in-order traversal Pre-order traversal # Parent -\u0026gt; Left child -\u0026gt; Right child\nCan be used to create a copy of the tree.\nRecursive def preorder_recursive(node): if node is None: return node.visit() preorder_recursive(node.left) preorder_recursive(node.right) Iterative # Since parents are visited prior to children, we can push to and pop from stack # in a loop as we go. The right child needs to pushed before left child so that # left child is popped first. def preorder_iterative(node): if node is None: return stack = [] stack.append(node) while stack: node = stack.pop() node.visit() if node.right: stack.append(node.right) if node.left: stack.append(node.left) Reverse pre-order traversal # Parent -\u0026gt; Right child -\u0026gt; Left child\nRecursive def reverse_preorder_recursive(node): if node is None: return node.visit() reverse_preorder_recursive(node.right) reverse_preorder_recursive(node.left) Iterative # Since parents are visited prior to children, we can push to and pop from stack # in a loop as we go. The left child needs to pushed before right child so that # right child is popped first. def reverse_preorder_iterative(node): if node is None: return stack = [] stack.append(node) while stack: node = stack.pop() node.visit() if node.left: stack.append(node.left) if node.right: stack.append(node.right) In-order traversal # Left child -\u0026gt; Parent -\u0026gt; Right child\nTraversing a binary search tree (BST) in-order will visit the nodes in sorted order (ascending). Other applications include construction of BST, creating balanced BST from sorted array, determining if a tree is balanced, and finding k-smallest elements in a BST.\nRecursive def inorder_recursive(node): if node is None: return inorder_recursive(node.left) node.visit() inorder_recursive(node.right) Iterative # Since left child has to be visited first, we need to push left children to the # stack until we reach a leaf node. We then start popping the nodes and after # visiting the popped nodes, push its right node, if it exist. If the right node # contains a subtree (could be even a complete subtree), this subtree will be # visited in-order as well. def inorder_ietrative(node): stack = [] while stack or node: if node: stack.append(node) node = node.left else: node = stack.pop() node.visit() node = node.right Reverse in-order traversal # Right child -\u0026gt; Parent -\u0026gt; Left child\nTraversing a binary search tree (BST) using reverse in-order method will visit the nodes in sorted order (descending). That means, it can be used to get K-largest elements in a BST as well.\nRecursive def reverse_inorder_recusrive(node): if node is None: return reverse_inorder_recusrive(node.right) node.visit() reverse_inorder_recusrive(node.left) Iterative # Since right child has to be visited first, we need to push right children to \\ # the stack until we reach a leaf node. We then start popping the nodes and # after visiting the popped nodes, push its left node, if it exist. If the # left node contains a subtree (could be even a complete subtree), this subtree # will be visited in-order as well. def reverse_inorder_iterative(node): stack = [] while stack or node: if node: stack.append(node) node = node.right else: node = stack.pop() node.visit() node = node.left Post-order traversal # Left child -\u0026gt; Right child -\u0026gt; Parent\nCan be used to delete tree from leaf to root.\nRecursive def postorder_recursive(node): if node is None: return postorder_recursive(node.left) postorder_recursive(node.right) node.visit() Iterative def postorder_iterative(node): stack = [] last_seen = None while stack or node: if node: stack.append(node) node = node.left else: peek_node = stack[-1] if peek_node.right and peek_node.right != last_seen: node = peek_node.right else: peek_node.visit() last_seen = stack.pop() Reverse post-order traversal # Right child -\u0026gt; Left child -\u0026gt; Parent\nRecursive def reverse_postorder_recursive(node): if node is None: return reverse_postorder_recursive(node.right) reverse_postorder_recursive(node.left) node.visit() Iterative def reverse_postorder_iterative(node): stack = [] last_seen_node = None while stack or node: if node: stack.append(node) node = node.right else: peek_node = stack[-1] if peek_node.left and peek_node.left != last_seen_node: node = peek_node.left else: peek_node.visit() last_seen_node = stack.pop() Test Code # graph TB; A((1))--\u003eB((2)) A--\u003eC((3)); B--\u003eE((4)) B--\u003eF((5)) C--\u003eH((6)) C--\u003eI((7)) E--\u003eM((null)) E--\u003eJ((8)) J--\u003eK((9)) J--\u003eL((10)) if __name__ == \u0026#39;__main__\u0026#39;: root = TreeNode(1) n2 = TreeNode(2) n3 = TreeNode(3) root.left = n2 root.right = n3 n4 = TreeNode(4) n5 = TreeNode(5) n2.left = n4 n2.right = n5 n6 = TreeNode(6) n7 = TreeNode(7) n3.left = n6 n3.right = n7 n8 = TreeNode(8) n4.right = n8 n9 = TreeNode(9) n10 = TreeNode(10) n8.left = n9 n8.right = n10 print(\u0026#34;In-order Recursive\u0026#34;) inorder_recursive(root) print(\u0026#34;In-order Iterarive\u0026#34;) inorder_ietrative(root) print(\u0026#34;Reverse In-order Recursive\u0026#34;) reverse_inorder_recusrive(root) print(\u0026#34;Reverse In-order Iterative\u0026#34;) reverse_inorder_iterative(root) print(\u0026#34;-------------------------\u0026#34;) print(\u0026#34;Pre-order recursive\u0026#34;) preorder_recursive(root) print(\u0026#34;Pre-order Iterative\u0026#34;) preorder_iterative(root) print(\u0026#34;Reverse Pre-order recursive\u0026#34;) reverse_preorder_recursive(root) print(\u0026#34;Reverse Pre-order Iterative\u0026#34;) reverse_preorder_iterative(root) print(\u0026#34;-------------------------\u0026#34;) print(\u0026#34;Post-order recursive\u0026#34;) postorder_recursive(root) print(\u0026#34;Post-order Iterative\u0026#34;) postorder_iterative(root) print(\u0026#34;Reverse Post-order recursive\u0026#34;) reverse_postorder_recursive(root) print(\u0026#34;Reverse Post-order Iterative\u0026#34;) reverse_postorder_iterative(root) Resources # A good resource to understand different tree traversal algorithms is Wikipedia. Also check EnjoyAlgorithms, StackOverflow and Testbook.\n"},{"id":5,"href":"/docs/dsa/data_structure/hash_table/","title":"Hash Table","section":"Data Structures","content":" Hash Table # "},{"id":6,"href":"/docs/dsa/data_structure/linked_list/traverse/","title":"Traverse","section":"Linked List","content":" Traverse linked list # Traverse the entire linked list # while head: head = head.next Traverse without modifying the head # Traverse with additional state variable # current_node = head while current_node: current_node = current_node.next Traverse with sentinel head only # sentinel_head = Node(None, head) while head: head = head.next return sentinel_head.next Traverse with sentinel head and tail # Traverse even nodes only / Skip every other node # even_node = head while even_node.next: even_node = even_node.next.next Traverse simultaneously at different speeds # Consistent speeds # slow_pointer = head fast_pointer = None while slow_pointer.next: slow_pointer = slow_pointer.next fast_pointer = slow_pointer.next.next Variable speed based on condition # Comment: Variable length sliding window\nTraverse with memory # Remember if value is seen before: # seen = set() # Why not use Python dictionary? current_node = head while current_node: if current_node.value not in seen: seen.add(current_node.value) current_node = current_node.next Comment: Detect duplicate values\nRemember node memory location (w/o duplicate values) # memory = {} # Why not use Python set? current_node = head while current_node: if current_node.value not in memory: memory[current_node.value] = current_node current_node = current_node.next Remember node memory location (w/ or w/o duplicate values) # memory = {} current_node = head while current_node: if current_node.value not in memory: memory[current_node.value] = [] memory[current_node.value].append(current_node) current_node = current_node.next Remember the most recent node with a duplicate value # memory = {} # Why not use Python set? current_node = head while current_node: if current_node.value not in memory: memory[current_node.value] = current_node current_node = current_node.next Comment: Cache implementation\n"},{"id":7,"href":"/docs/dsa/data_structure/binary_tree/delete/","title":"Delete","section":"Binary Tree","content":" Delete node # "},{"id":8,"href":"/docs/dsa/data_structure/linked_list/delete/","title":"Delete","section":"Linked List","content":" Delete node from linked list # "},{"id":9,"href":"/docs/dsa/data_structure/linked_list/update/","title":"Update","section":"Linked List","content":" Update # "},{"id":10,"href":"/docs/dsa/data_structure/binary_tree/problems/","title":"Problems","section":"Binary Tree","content":" Binary Search Tree Iterator # Implement the BSTIterator class that represents an iterator over the in-order traversal of a binary search tree (BST):\nBSTIterator(TreeNode root) Initializes an object of the BSTIterator class. The root of the BST is given as part of the constructor. The pointer should be initialized to a non-existent number smaller than any element in the BST. boolean hasNext() Returns true if there exists a number in the traversal to the right of the pointer, otherwise returns false. int next() Moves the pointer to the right, then returns the number at the pointer. Notice that by initializing the pointer to a non-existent smallest number, the first call to next() will return the smallest element in the BST.\nYou may assume that next() calls will always be valid. That is, there will be at least a next number in the in-order traversal when next() is called.\nApproach 1: Flattening the BST\n# Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class BSTIterator: def __init__(self, root: Optional[TreeNode]): self.sorted_nodes = [] self.index = -1 self._inorder(root) def _inorder(self, root): if not root: return self._inorder(root.left) self.sorted_nodes.append(root.val) self._inorder(root.right) def next(self) -\u0026gt; int: self.index += 1 return self.sorted_nodes[self.index ] def hasNext(self) -\u0026gt; bool: return self.index + 1 \u0026lt; len(self.sorted_nodes) Approach 2: Controlled Recursion\nclass BSTIterator: def __init__(self, root: Optional[TreeNode]): self.stacked_nodes = [] self._left_inorder(root) def _left_inorder(self, root): if not root: return self.stacked_nodes.append(root) self._left_inorder(root.left) def next(self) -\u0026gt; int: node = self.stacked_nodes.pop() if node.right: self._left_inorder(node.right) return node.val def hasNext(self) -\u0026gt; bool: return len(self.stacked_nodes) \u0026gt; 0 "},{"id":11,"href":"/docs/dsa/data_structure/linked_list/problems/","title":"Problems","section":"Linked List","content":" Coding Problems # Detect cycles in a linked list # Remove duplicates in a sorted linked list # Keep the first node # Keep the last node # Remove all duplicates # Remove duplicates in an unsorted linked list # Keep the first node # Keep the last node # Remove all duplicates # Remove k-th last node # Remove k-th node from i-th node # "},{"id":12,"href":"/docs/dsa/data_structure/binary_tree/","title":"Binary Tree","section":"Data Structures","content":" Binary Tree # class BinaryTree: self.root = None self.depth = None class Node: self.value = None self.left = None # left child self.right = None # right child This StackOverflow thread has a list of applications where binary trees are used.\n"},{"id":13,"href":"/docs/dsa/data_structure/heap/","title":"Heap","section":"Data Structures","content":" Heap # "},{"id":14,"href":"/docs/dsa/data_structure/stack/","title":"Stack","section":"Data Structures","content":" Stack # "},{"id":15,"href":"/docs/systems/os/booting/","title":"Booting","section":"Operating Systems","content":" How do computers boot up? # When we power up a computer, how does it know where to find an operating system? How does a computer identify that a particular program or executable file is an operating system and decide it will have the privilege to control the system? How does it know how to boot an entire operating system which may consist of more than a single executable file? How does an operating system take control of the system?\nAmplification Predefined address translation and file format Hierarchical search paths Privileged mode and interrupt vector Dror G. Feitelson described the main idea behind booting a system as amplification. It means that we start by executing a very short program that will load a bigger program, which can then load other longer programs. The immediate questions would be – How would we load the first short program? How short does it have to be? How would it know where to look for the subsequent program? What will happen if any of these were to be updated?\nThe idea that solves the problem of loading the first executable is predefined address translation. We’ll always start executing instructions stored in a particular hardware (e.g., a non-volatile Read-Only Memory) at a predefined physical memory location (e.g., the first physical block of the primary storage device aka boot sector, when loading the boot loader), after we turn on a computer. But a single byte or a block definitely can’t store all information about how to load the entire executable, which can vary in size in different systems or even in different versions of the same system. Since a files system is yet to be initialized, how would the short program know how to load the next executable file correctly?\nThe above problem can be solved simply by following a predefined file format, where a fixed number of bytes at the beginning will contain the information about the executable, followed by the entry point for the executable instructions. Let’s say, we use the first four bytes to provide information about the executable and the fifth byte contains the first instruction to be executed. We can then execute the instructions in sequence. In case of a computer, the first program (small enough to fit inside the computer’s ROM) can load a boot loader, that will start loading the actual operating system. The boot loader will use the same principles to look for the entry point of the operating system and load it, which will then load another system and the chain will be amplified until the operating systems and it’s services start. Stephen Marz provides an hands-on example of how this is done on a RISC-V machine, for an operating system written in Rust.\nAnother related idea is hierarchical search paths. What will happen if we have multiple candidates in any stage of the whole process? For example, if the first executable can search for the entry point in multiple storage devices, which one should it look for first and if there are multiple boot loaders present in the system, which one should it pick. The search path is also predefined, but by the user. In case of a computer, if a boot loader is found in the first path, then the search will end immediately. If the boot loader finds multiple operating systems in a computer, it usually let’s the user choose which one to boot.\nHow can we boot up the computer if the none of the above exist? In early computers, the first short program (i.e., the initial instructions – the opcodes and the arguments) were entered manually using switches of the computer, after turning it on. The next big ideas are privileged mode and interrupt vector. The boot loader loads the kernel of the operating system in privileged mode(s) of the CPU (the exact name of the mode can be different in different instruction sets). It also loads the interrupt vector that contains all entry points to the operating system in a predefined memory location. Once the kernel of the operating system is loaded, it can be switch to user mode with lower privilege to load other services and programs. It should be noted that the privileged mode(s) and interrupt vectors are CPU features that let a program gain control of the system. Once a program (in this case the operating system kernel) loads the interrupt vector and switch to user mode, request for all privileged operations will be redirected to and executed by the operating system kernel and the latter can always regain control of the system from any program running on the system in user mode. If we want some other program to take control of the system during boot, then we need to overwrite or update the boot loader to point to the new program. If we want a program to override the operating system without rebooting, we would need to do so by finding a security vulnerability in the operating system code that’ll let us overwrite the interrupt vector to point to our preferred memory locations.\nAn operating system manages computer systems designed based on a specific abstract model of a computer. This abstract model includes an Instruction Set Architecture (ISA) that defines what the CPU can do and how to interact with the CPU. In other words, an operating system is written with a specific computer model or ISA in mind and how we initialize the operating system is dependent on the features of that computer model or ISA. To summarize, upon turning on a device, we need to start executing instructions from a specific physical address and execute the instructions in sequence. The initial sets of instructions (i.e., the first program) loads a bigger program from another predefined address. All of these goes in a predefined hierarchical order in the privileged mode of the CPU, until the operating system kernel is loaded. Once the operating system takes control of the CPU, it can then switch to less privileged user mode to start different services. ByteByteGo has a nice article describing how Linux operating system boots in a single boot system. For more information about privileged and user mode for RISC-V once can take a look at RISC-V ISA manual. Intel CPUs have multiple privilege modes and complicated privilege switching mechanism due to backward compatibility.\nDo other devices (e.g., SSD, GPU, or any complex electronic device) use to same techniques to initialize their internal software (i.e., firmware, operating system or whatever it is)? While booting up the firmware of any hardware inside a computer (e.g., SSD, GPU, network adapter, even the CPU) is simpler, some of above ideas apply. However, most firmware inside these devices may not need to implement complicated interrupt-based privilege escalation/de-escalation similar to the operating system. It is worth investigating whether or not this is true for computational SSDs that can run compute inside the storage device.\nHow to change default kernel in Linux? # # Get the index of the kernel $ sudo grubby --info=ALL # Change value of GRUB_DEFAULT with correct index $ sudo nano /etc/default/grub # Update grub and reboot $ sudo grub2-mkconfig -o /boot/grub2/grub.cfg # CentOS $ sudo update-grub # Ubuntu $ sudo reboot "},{"id":16,"href":"/docs/ml/checkpointing/checkfreq/","title":"CheckFreq","section":"Checkpointing","content":" Implementing CheckFreq\u0026rsquo;s asynchronous ML checkpointing in Darknet # I have recently implemented CheckFreq, an asynchronous checkpointing library for Deep Neural Networks (DNN), on top of Darknet, an open source neural network framework written in C and CUDA. Below are some high-level details about the implementation and one important lesson about CUDA concurrency.\nDarknet handles model checkpointing synchronously, where a checkpoint can only start after the weight update completes in an iteration and the next iteration does not start until the checkpoint operation completes. In contrast, CheckFreq proposes an two-stage asynchronous checkpointing method where the checkpoint operation executes in the background and only the weight update operation of the next iteration has to wait until the first stage (i.e., the snapshot operation that copies the model state in new memory pages in GPU or CPU) completes. This wait is called the snapshot stall. The second stage (i.e., the persist stage that writes the model state in GPU or CPu memory to files in persistent storage) can execute in the background without blocking any other operation. Implementing this correctly in Darknet involved three things.\nBackground threads Thread synchronization using conditional variables CUDA streams for concurrency\nI created two threads – one for training and one for checkpointing – from the main() function in Darknet. I used a global variable keeps track of checkpoint state and two conditional variables for synchronizing the training and checkpointing threads – one for signalling weight update has finished and a new checkpoint can be triggered and another for signalling snapshot has completed and the weight update can start. Implementing the synchronization between two threads needed some effort due to multiple bugs related to checkpoint state and memory access. Once the bugs are rooted out, I saw that the overall iteration time with and without snapshot stalls are as expected.\nHowever, what was really challenging was to figure out a CUDA concurrency issue that was stalling the wrong operation in the training thread. The timing information of each operation inside an iteration – data loading time, forward-backward pass, weight update, and snapshot stall – showed that weight updates were not stalling while a snapshot operation was ongoing. Instead, it is the forward-backward pass operation that was stalling. The issue stems from the use of a single CUDA stream for data transfer in each GPU in Darknet. Since the snapshot operation, training data loader and the forward-backward pass uses the same stream for data transfer, data for the next iteration doesn’t complete the host to device transfer of input training data until the snapshot operation finishes its device to host data transfer of model state. Once I identified this issue, the solution was simple enough – use separate CUDA streams to enable concurrent data transfers for two independent operations – snapshot and data loader.\nI’ll put the code online some time in future.\nBuilding CheckFreq Docker image # Use CC-Ubuntu20.04-CUDA-20230831.1 image in Chameleon Cloud. Install Docker and Nvidia Container Toolkit. # https://docs.docker.com/engine/install/ubuntu/ # Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update # Install the latest version sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-20-04 # To use docker command without sudo. Logout and log back in after executing the following command. sudo usermod -aG docker ${USER} # Install Nvidia Docker Toolkit sudo apt-get install -y nvidia-container-toolkit Pull Dokcer image nvcr.io/nvidia/pytorch:19.05-py3. docker pull nvcr.io/nvidia/pytorch:19.05-py3 Pull DS-Analyzer(optional), CoorDL and CheckFreq repositories. Copy patch for resumable iterator from CheckFreq repo to CoorDL repo. Apply the patch. git clone git@github.com:msr-fiddle/DS-Analyzer.git git clone --recursive https://github.com/msr-fiddle/CoorDL git clone git@github.com:msr-fiddle/CheckFreq.git cp CheckFreq/dl_patch/resumable_iterator.patch CoorDL/ cd CoorDL git apply resumable_iterator.patch Update Dockerfile named Docker_run_cuda in CoorDL repo. Comment line 34. Add hdparm in the install list. Update docker/build.sh in CoorDL repo. Update CUDA_IMAGE_NAME in line 200. export CUDA_IMAGE_NAME=\u0026#34;nvcr.io/nvidia/pytorch:19.05-py3\u0026#34; #export CUDA_IMAGE_NAME=\u0026#34;nvcr.io/nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\u0026#34; Build the docker image py36_cu10.run. CREATE_RUNNER=\u0026#34;YES\u0026#34; ./build.sh Run the Docker image using the following command. docker run --gpus all --ipc=host --mount src=/,target=/datadrive/,type=bind -it --rm --network=host --privileged nvidia/dali:py36_cu10.run Useful commands:\n# restart Docker sudo systemctl restart docker # View Docker images docker image ls # Delete docker image by ID docker image rm \u0026lt;IMAGE ID\u0026gt; Some processes running on GPU may terminate inside the container but continue running on the host side. Use sudo kill \u0026lt;pid\u0026gt; to kill the process.\nChameleon\u0026rsquo;s Ubuntu image mentioned in step 0 can throw Failed to initialize NVML: Driver/library version mismatch error at some point. To prevent this from happening in Ubuntu, stop automatical update of NVIDIA drivers. Add the following in sudo nano /etc/apt/apt.conf.d/50unattended-upgrades.\nUnattended-Upgrade::Package-Blacklist { \u0026#34;nvidia-\u0026#34;; \u0026#34;libnvidia-\u0026#34;; ... } "},{"id":17,"href":"/docs/systems/storage/cxl/","title":"Compute Express Link (CXL)","section":"Storage Systems","content":" Compute Express Link (CXL) # CXL Specs, Protocols, Device Types # CXL specifications have three major versions so far - CXL 1.0, CXL 2.0 and CXL 3.0. These CXL specifications also supports three sub-protocols - CXL.io, CXL.cache and CXL.mem. Apart from protocols, CXL specifications also defines three device types - Type 1, Type 2 and Type 3.\nType 1 devices are specialized accelerators (e.g., smart NIC) with no local memory and rely on coherent access to host CPU memory using CXL.io and CXL.cache sub-protocols. Type 2 devices are general-purpose accelerators (e.g., GPU) with local memory that can coherently access host CPU memory and provide coherent or non-coherent access to device local memory using CXL.io, CXL.cache and CXL.mem sub-protocols. Type 3 CXL devices are memory expanders (e.g., CXL-attached DRAM) that allow access to device local memory using the CXL.io and CXL.mem sub-protocols.\nDifferent versions of the CXL specifications defines and refines the sub-protocols used to access and manage CXL devices and how these devices interact with other CXL and non-CXL devices in local and/or remote systems.\nSource: Wikipedia\nCXL I/O Path # Source: ACM\nSource: Semiconductor Engineering\nSource: CXL Consortium\nSource: servethehome.com\nTools to configure CXL-attached Memory # CXL Memory Resource Kit (CMRK) CXL-attached Memory Device List [Sep 2024] # Kioxia CXL+BiCS Flash SSD Samsung CMM-D Samsung CMM-H Micron CZ120 memory expansion module Smart CXL Add-in Card Astera Labs CXL controller "},{"id":18,"href":"/docs/systems/os/cpu/","title":"CPU","section":"Operating Systems","content":" CPU # How does the OS send instructions to CPU? How does the OS take control of the CPU? Does CPU have it\u0026rsquo;s own OS internally? Does CPU recognize OS process or thread? Does CPU recognize OS process or thread? # Software process and threads are abstractions introduced by the OS. CPU may or may not recognize processes and software threads. For example, Arm provides registers to store processor and thread IDs for OS management purpose. In contrast, CPUs can have hardware threads (e.g., hart in CPUs based on RISC-V). Hardware threads can be thought of as logical CPU cores. The question is, how does OS implement and manage processes and software threads if CPU does not recognize these abstractions?\nSources: RISC-V, Reddit(1), Reddit(2)\n"},{"id":19,"href":"/docs/systems/cross_cutting_issues/","title":"Cross Cutting Issues","section":"Computer Systems","content":" Cross Cutting Issues in Computer Systems # "},{"id":20,"href":"/docs/systems/cross_cutting_issues/alignment/","title":"Data Access Alignment","section":"Cross Cutting Issues","content":" Are data accesses in computer systems byte-aligned or block-aligned? # "},{"id":21,"href":"/docs/systems/cross_cutting_issues/device_driver/","title":"Device Driver","section":"Cross Cutting Issues","content":" Device Driver # Does OS needs a device driver to communicate with CPU? # What about supporting advanced CPU features or instruction sets?\nDo DRAM devices need drivers? # How come we do not need to install any new driver even if we install DRAM from unknown manufacturers? Are these drivers generic?\nWhat role IOCTL plays in device drivers? # "},{"id":22,"href":"/docs/systems/storage/dax/","title":"Direct Access (DAX)","section":"Storage Systems","content":" Direct Access (DAX) # DAX I/O Path # Source: Pmem.io\nSource: StorageReview\nFSDAX vs. DEVDAX # "},{"id":23,"href":"/docs/systems/os/io_path/","title":"I/O Path","section":"Operating Systems","content":" How are data accessed in computer systems? # Linux Storage Stack Diagram # Source: Wikipedia\nDirect Access (DAX) I/O Path # Source: Pmem.io\nSource: StorageReview\nTiered-memory I/O Path # Source: StorageReview\nCXL I/O Path # Source: ACM\nSource: Semiconductor Engineering\nSource: CXL Consortium\nKey-Value SSD I/O Path # Source: SemanticScholar\nHow does DMA work? # What is PCIe root? What role does it play in transferring data to/from PCIe-attached devices? # "},{"id":24,"href":"/docs/dsa/algorithm/sorting/","title":"Sorting","section":"Algorithms","content":" Sorting # Comparison-based sorting Stable sorting In-place sorting What is a stable sorting algorithm? # Sorting algorithms that maintain the relative order of records with equal keys are called stable.\nRef: Baeldung\nComparison Table # Merge sort Quick sort Cyclic sort Topological sort Comparison-based ✓ ✓ ✓ ✓ Stable ✓ ✗ ✗ In-place ✗ ✓ Time complexity nlog(n) O(n) Space complexity O(n) O(1) Constraints Applications Comments Cyclic Sort # Cyclic sort is not stable.\nWhy is it called cyclic? Because this sorting technique can only be applied on cycles within an array or list. Cycles are nothing but subsequences of unsorted elements. A cycle occurs when there is an element in the array/list out-of-place, and moving the element to its correct position in the array/list moves another element to the former element\u0026rsquo;s place, forming a cycle.\nWhere should we use cyclic sort?\nCan we use cyclic sort where the elements are not consecutive numbers (e.g., 1-n)? Can we use if the elements are not in a subsequence? Cyclic sort can be used to sort elements in a subsequence. In case of integer arrays, it is not encessary that the elements in a subsequence are consecutive integers (e.g., 1,2,3,4). As long as the integers in a subsequence form a series it can sorted using cyclic sort (e.g., 2, 4, 6)\nWhat is a subsequence? Is it different from a cycle?\nProblems # How to make a non-stable sort into a stable sort? # How to make an in-place sort into an in-place sort? # How does each of the above sorting algorithm behave with duplicate elements? # Implement a non-comparison sorting algorithm # Merge k-sorted arrays # (a) Out-of-place (i.e., when new memory allocations are allowed)\n(b) In-place (i.e., when one array is large enough to hold all arrays and has empty slots)\n(c) Compute intersection of k-sorted arrays\nCan we use the same solutions for the above problems if the data structure is list, instead of array?\nSorting lists # (a) Implement a fast sorting algorithm for lists\nSorting with duplicates # (a) Sort array with duplicate values\n(b) Remove first-name duplicates\n(c) Partitioning and sorting an array with repeated entries\n"},{"id":25,"href":"/docs/systems/storage/ssd_data_structures/","title":"SSD Data Structures","section":"Storage Systems","content":" Data structures inside SSD Flash Translation Layer (FTL) # [I’ll edit this article in multiple iterations.]\nLets’ start with a brief overview of data structure groupings by FTL component or function. Please keep in mind that some data structures are used by multiple FTL componens or functions.\nAddress mapping Direct mapping table Mapping cache Global Mapping Directory (GMD) Reverse mapping Garbage Collection Block validity counter (BVC) Page validity counter (PVC) Transaction processing Free block list Data cache Chip queue Wear Leveling Bad block management FTL recovery/restore "},{"id":26,"href":"/docs/ml/datasets/tiny_imagenet/","title":"Tiny ImageNet","section":"Datasets","content":" Tiny ImageNet # Can be used as a substitute of ImageNet dataset. It has 200 classes with image sizes of 64x64 pixels. Test set is not labeled. Validation set needs to be used as test set. Validation set needs some preprocessing before it can be used for evaluating the model. Directly passing the images to application will result in incorrect validation/test accuracy.\nDownload dataset # wget http://cs231n.stanford.edu/tiny-imagenet-200.zip Create Dataloader # There are two ways to create data loaders for Tiny ImageNet. One is using torchvision.datasets.ImageFolder and the other is through Python dictionary.\nUsing torchvision.datasets.ImageFolder # # Modified from https://github.com/DennisHanyuanXu/Tiny-ImageNet/blob/master/src/data_prep.py import os, glob import torch import torchvision import torchvision.transforms as transforms from torch.utils.data import DataLoader from torch.utils.data import Dataset from torchvision import datasets def create_val_img_folder(configs): \u0026#39;\u0026#39;\u0026#39; This method is responsible for separating validation images into separate sub folders \u0026#39;\u0026#39;\u0026#39; # dataset_dir = os.path.join(args.data_dir, args.dataset) val_dir = os.path.join(configs.data_path, \u0026#39;val\u0026#39;) img_dir = os.path.join(val_dir, \u0026#39;images\u0026#39;) fp = open(os.path.join(val_dir, \u0026#39;val_annotations.txt\u0026#39;), \u0026#39;r\u0026#39;) data = fp.readlines() val_img_dict = {} for line in data: words = line.split(\u0026#39;\\t\u0026#39;) val_img_dict[words[0]] = words[1] fp.close() # Create folder if not present and move images into proper folders for img, folder in val_img_dict.items(): newpath = (os.path.join(img_dir, folder)) if not os.path.exists(newpath): os.makedirs(newpath) if os.path.exists(os.path.join(img_dir, img)): os.rename(os.path.join(img_dir, img), os.path.join(newpath, img)) # Use either load_tiny_imagenet1() or load_tiny_imagenet2() def load_tiny_imagenet1(configs): create_val_img_folder(configs) train_dir = os.path.join(configs.data_path, \u0026#39;train\u0026#39;) val_dir = os.path.join(configs.data_path, \u0026#39;val\u0026#39;, \u0026#39;images\u0026#39;) # kwargs = {} if args.no_cuda else {\u0026#39;num_workers\u0026#39;: 1, \u0026#39;pin_memory\u0026#39;: True} # Pre-calculated mean \u0026amp; std on imagenet: # norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # For other datasets, we could just simply use 0.5: # norm = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalization norm = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) train_trans = [transforms.RandomHorizontalFlip(), transforms.ToTensor()] val_trans = [transforms.ToTensor(), norm] train_data = datasets.ImageFolder(train_dir, transform=transforms.Compose(train_trans + [norm])) val_data = datasets.ImageFolder(val_dir, transform=transforms.Compose(val_trans)) print(train_data) print(val_data) train_loader = torch.utils.data.DataLoader(train_data, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) val_loader = torch.utils.data.DataLoader(val_data, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) print(\u0026#39;Number of iterations required to get through training data of length {}: {}\u0026#39;.format( len(train_data), len(train_loader))) return {\u0026#39;train\u0026#39;: train_loader, \u0026#39;test\u0026#39;: val_loader} def load_tiny_imagenet2(configs): create_val_img_folder(configs) # transform for the training data train_transforms = transforms.Compose([ transforms.Resize(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) val_transforms = transforms.Compose([ transforms.Resize(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) train_data_path = configs.data_path + \u0026#34;/train/\u0026#34; val_data_path = configs.data_path + \u0026#34;/val/images/\u0026#34; train_set = datasets.ImageFolder(train_data_path, transform=train_transforms) val_set = datasets.ImageFolder(val_data_path, transform=val_transforms) train_loader = torch.utils.data.DataLoader(train_set, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) val_loader = torch.utils.data.DataLoader(val_set, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) print(\u0026#39;Number of iterations required to get through training data of length {}: {}\u0026#39;.format( len(train_set), len(train_loader))) return {\u0026#39;train\u0026#39;: train_loader, \u0026#39;test\u0026#39;: val_loader} Using torchvision.io.read_image and Python dictionary # # https://github.com/pranavphoenix/TinyImageNetLoader/blob/main/tinyimagenetloader.py import os, glob import torch import torchvision import torchvision.transforms as transforms from torch.utils.data import DataLoader from torch.utils.data import Dataset from torchvision import datasets from torchvision.io import read_image, ImageReadMode id_dict = {} class TrainTinyImageNetDataset(Dataset): def __init__(self, data_path, id, transform=None): self.data_path = data_path + \u0026#34;/*/*/*.JPEG\u0026#34; self.filenames = glob.glob(self.data_path) self.transform = transform self.id_dict = id def __len__(self): return len(self.filenames) def __getitem__(self, idx): img_path = self.filenames[idx] image = read_image(img_path) if image.shape[0] == 1: image = read_image(img_path,ImageReadMode.RGB) print(img_path) label = self.id_dict[img_path.split(\u0026#39;/\u0026#39;)[-3]] if self.transform: image = self.transform(image.type(torch.FloatTensor)) return image, label class TestTinyImageNetDataset(Dataset): def __init__(self, data_path, id, transform=None): self.data_path = data_path + \u0026#34;/images/*.JPEG\u0026#34; self.filenames = glob.glob(self.data_path) self.transform = transform self.id_dict = id self.cls_dic = {} self.val_annotation = data_path + \u0026#34;/val_annotations.txt\u0026#34; for i, line in enumerate(open(self.val_annotation, \u0026#39;r\u0026#39;)): a = line.split(\u0026#39;\\t\u0026#39;) img, cls_id = a[0],a[1] self.cls_dic[img] = self.id_dict[cls_id] def __len__(self): return len(self.filenames) def __getitem__(self, idx): img_path = self.filenames[idx] image = read_image(img_path) if image.shape[0] == 1: image = read_image(img_path,ImageReadMode.RGB) label = self.cls_dic[img_path.split(\u0026#39;/\u0026#39;)[-1]] if self.transform: image = self.transform(image.type(torch.FloatTensor)) def load_tiny_imagenet_dict(configs): # transform for the training data data_path = configs.data_path + \u0026#34;/wnids.txt\u0026#34; for i, line in enumerate(open(data_path, \u0026#39;r\u0026#39;)): id_dict[line.replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;)] = i train_transforms = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) train_data_path = configs.data_path + \u0026#34;/train/\u0026#34; val_data_path = configs.data_path + \u0026#34;/val_dict/\u0026#34; train_set = TrainTinyImageNetDataset(data_path=train_data_path, id=id_dict, transform = train_transforms) val_set = TestTinyImageNetDataset(data_path=val_data_path, id=id_dict, transform=train_transforms) train_loader = torch.utils.data.DataLoader(train_set, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) val_loader = torch.utils.data.DataLoader(val_set, batch_size=configs.batch_size, num_workers=configs.num_workers, shuffle=True) print(\u0026#39;Number of iterations required to get through training data of length {}: {}\u0026#39;.format( len(train_set), len(train_loader))) return {\u0026#39;train\u0026#39;: train_loader, \u0026#39;test\u0026#39;: val_loader} Set num_classes=200 # Do not forget to set num_classes=200 in your model. Otherwise Pytorch may throw an error RuntimeError: CUDA error: device-side assert triggered if the application is run using the following command.\nCUDA_LAUNCH_BLOCKING=1 python3 \u0026lt;application_file_name\u0026gt;.py Remove \u0026lt;label\u0026gt;_boxes.txt files # To remove \u0026lt;label\u0026gt;_boxes.txt files for training images, use the following bash script.\n#!/bin/bash parent=\u0026#34;train\u0026#34; cd \u0026#34;$parent\u0026#34; for DIR in */ do echo $DIR cd \u0026#34;$DIR\u0026#34; rm -f *.txt if test -d ./images then cd ./images mv * ../ cd .. rm -r ./images fi cd .. done Why upsample images? # Tiny ImageNet samples are of 64x64 pixels. Whereas, models like ResNet 50 or resNet152 needs inputs sizes 224x224 pixels. When training from scratch, it is possible to reduce the input size in the models being used to 64x64 (e.g. VGG-16, ResNet50, Resnet152), eliminating the need for resizing the images by the dataloader. This is, however, may not be possible in pre-trained models. Interestingly, some people mentioned that reducing the input size to 64x64 pixels in the above mentioned models has resulted in lower model accuracy in their experiments. From my experience, reducing the input size can lower computations and significantly increase training speed. Take a look at this discussion thread.\n"}]